nohup: 忽略输入
logging improved.
[2024-09-18 15:53:39,786] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-18 15:53:40.342068: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-18 15:53:40.344973: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-09-18 15:53:40.387674: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-18 15:53:40.387703: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-18 15:53:40.387728: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-18 15:53:40.395776: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-09-18 15:53:40.396058: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-09-18 15:53:41.567578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/wangzhen/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
ControlLDM: Running in eps-prediction mode
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.
DiffusionWrapper has 859.52 M params.
making attention of type 'vanilla-xformers' with 512 in_channels
building MemoryEfficientAttnBlock with 512 in_channels...
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
making attention of type 'vanilla-xformers' with 512 in_channels
building MemoryEfficientAttnBlock with 512 in_channels...
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.
Loaded model config from [./models/cldm_v15.yaml]
Loaded state_dict from [./models/control_sd15.ckpt]
Module Name: time_embed, Module Type: <class 'torch.nn.modules.container.Sequential'>
Module Name: input_blocks, Module Type: <class 'torch.nn.modules.container.ModuleList'>
Module Name: middle_block, Module Type: <class 'ldm.modules.diffusionmodules.openaimodel.TimestepEmbedSequential'>
Module Name: output_blocks, Module Type: <class 'torch.nn.modules.container.ModuleList'>
Module Name: out, Module Type: <class 'torch.nn.modules.container.Sequential'>
TimestepEmbedSequential(
  (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
---------------------------------------------------------------------------------------
Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Parameter containing:
tensor([[[[-0.0277,  0.0743,  0.0868],
          [-0.0259, -0.1974,  0.1299],
          [-0.0209, -0.0178,  0.0277]],

         [[ 0.0527, -0.0802, -0.0055],
          [ 0.1813, -0.1248, -0.0129],
          [ 0.0112, -0.0022, -0.0055]],

         [[ 0.0291, -0.0137,  0.0392],
          [-0.0227,  0.0670,  0.0718],
          [ 0.0017, -0.0083, -0.0356]],

         [[ 0.0178, -0.0427,  0.0399],
          [ 0.0537, -0.1325,  0.0838],
          [ 0.0111, -0.0158,  0.0396]]],


        [[[ 0.0067, -0.0242, -0.0415],
          [ 0.0009,  0.0358,  0.0958],
          [-0.0066,  0.0130,  0.0178]],

         [[ 0.0033,  0.0097, -0.0096],
          [-0.0003,  0.0778,  0.0078],
          [-0.0003,  0.0401,  0.0293]],

         [[ 0.0041,  0.0554,  0.0144],
          [ 0.0290, -0.2050,  0.0255],
          [ 0.0178, -0.0555,  0.0137]],

         [[-0.0215, -0.0397,  0.0133],
          [-0.0195,  0.0732,  0.0030],
          [-0.0215,  0.0121, -0.0248]]],


        [[[-0.0574, -0.0881, -0.0252],
          [ 0.0350,  0.0477, -0.0006],
          [ 0.0336,  0.0587,  0.0354]],

         [[-0.0174,  0.0733,  0.0360],
          [ 0.0229, -0.0809, -0.0470],
          [-0.0097,  0.0185, -0.0048]],

         [[-0.0088,  0.0701, -0.0147],
          [-0.0661,  0.1956, -0.0242],
          [-0.0039, -0.0777, -0.0057]],

         [[-0.0083, -0.0071, -0.0055],
          [-0.0122,  0.0617,  0.0588],
          [-0.0389,  0.0230, -0.0192]]],


        ...,


        [[[-0.0246,  0.0539, -0.0010],
          [ 0.0028,  0.0786, -0.0109],
          [ 0.0049, -0.0345,  0.0101]],

         [[ 0.0198,  0.0138,  0.0345],
          [ 0.0480,  0.0742, -0.0213],
          [-0.0099,  0.0358, -0.0042]],

         [[ 0.0260,  0.0058,  0.0069],
          [ 0.0562,  0.0179,  0.0940],
          [ 0.0258, -0.0184,  0.0765]],

         [[ 0.0623,  0.0428,  0.0413],
          [ 0.0496, -0.0971,  0.0154],
          [ 0.0141, -0.0012,  0.0360]]],


        [[[-0.0080,  0.0128,  0.0239],
          [ 0.0523, -0.0235,  0.0471],
          [ 0.0052,  0.0703, -0.0411]],

         [[-0.0340, -0.0097,  0.0171],
          [ 0.0422,  0.0527,  0.0422],
          [ 0.0279,  0.0321, -0.0062]],

         [[ 0.0722, -0.0130,  0.0497],
          [-0.0166,  0.0410, -0.0086],
          [-0.0512, -0.1150, -0.0875]],

         [[-0.0048,  0.0076, -0.0166],
          [ 0.0224, -0.0093,  0.0033],
          [ 0.0440,  0.0739,  0.0037]]],


        [[[-0.1191, -0.0775,  0.0019],
          [ 0.0876, -0.0176,  0.0412],
          [ 0.0529,  0.0337,  0.0539]],

         [[ 0.1081,  0.0398,  0.0082],
          [ 0.0433, -0.0084, -0.0080],
          [-0.0880,  0.0224, -0.0451]],

         [[-0.0517, -0.0443, -0.0199],
          [-0.0199,  0.0563, -0.0251],
          [ 0.0208,  0.0167, -0.0080]],

         [[-0.0397, -0.0417, -0.0073],
          [ 0.0334,  0.0243,  0.0279],
          [ 0.0490, -0.0015,  0.0121]]]], requires_grad=True)
Traceback (most recent call last):
  File "/home/wangzhen/ControlNet/demo_train.py", line 57, in <module>
    model.model.diffusion_model.register_to_config(in_channels=in_channels)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'ControlledUnetModel' object has no attribute 'register_to_config'
